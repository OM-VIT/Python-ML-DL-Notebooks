{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Clothes Image Classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OM-VIT/Python-Machine-Learning-Notebooks/blob/main/Clothes_Image_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label Computer Vison Classification"
      ],
      "metadata": {
        "id": "q3CGphLtEjO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook explores FastAI and PyTorch to model an image recognition application. The dataset provided [here](https://www.kaggle.com/agrigorev/clothing-dataset-full) contains 5000 high resolution images of clothes. The model is designed based on this dataset to distinguish among various types of clothing. Unlike the other datasets, this has 2 different variables identifying the piece of clothing - the first variable determines if the image contains a children's clothing and the second variable names the item. After the model has been designed, iPython widgets are used to test the model which can then be deployed onto a server for full functioning end-to-end application."
      ],
      "metadata": {
        "id": "SsJVYtE6EjPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from fastai.vision.all import *\n",
        "from fastai.vision.widgets import *\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "qlBnNdhQEjPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset provided has 2 subsets - one with thee original images and 20 classes, and the other with resized images and only top 10 classes. This notebook uses the original dataset."
      ],
      "metadata": {
        "id": "sr5gs3xSEjPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "ziJSGWSIEjPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset \n",
        "labels = pd.read_csv('/kaggle/input/clothing-dataset-full/images.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "lBrEnq3OEjPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "FpjHYyeLEjPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'image' column contains the names of the images. This will be mapped to the folder they are stored at to access them while creating the model. The 'label' column identifies the piece of clothing whereas the 'kids' column identifies if the clothing is for children or not."
      ],
      "metadata": {
        "id": "yG_YVO2CEjPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes and their counts within the dataset\n",
        "labels['label'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "XPcifVS3EjPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace 'Not sure' with 'Not_sure'."
      ],
      "metadata": {
        "id": "Ufa3z4onEjPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels.loc[labels['label']=='Not sure','label'] = 'Not_sure'"
      ],
      "metadata": {
        "trusted": true,
        "id": "HqmbJMgyEjPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add suffix '.jpg' to all image files in the dataframe to open them within the model."
      ],
      "metadata": {
        "id": "7deeHWXtEjPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels['image'] = labels['image'] + '.jpg'"
      ],
      "metadata": {
        "trusted": true,
        "id": "-SSfrfZ1EjPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge the two lables 'label' and 'kids' into one column using space as a delimiter."
      ],
      "metadata": {
        "id": "F9164AR_EjPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels['label_cat'] = labels['label'] + ' ' + labels['kids'].astype(str)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RSIFjp3jEjPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep only the images and their labels for the model to process."
      ],
      "metadata": {
        "id": "aob_KH6REjPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_df = labels[['image', 'label_cat']]"
      ],
      "metadata": {
        "trusted": true,
        "id": "MIeVmu2eEjPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "H3rLc7hrEjPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the dataframe is cleaned and ready to develop the model, it has to be transformed in a way that can be used to create the model. We are using FastAIs Convolusional Neural Network classifier 'resnet18'. This CNN has 18 layers with pretrained weights. \n",
        "\n",
        "The input to create the learner is a dataloader and the model 'resnet18'. The learner uses 'accuracy_multi', which calculates the accuracy for a multi-category dataset using a specified threshold. The threshold by default is 0.5, but for this model, we can start at 0.2 and then test the outcome of other threshold values. \n",
        "\n",
        "To create the dataloader, we need to have a DataBlock that will identify the dependent (labels) and the independent (images) variables using the MultiCategoryBlock and ImageBlock respectively. Using ImageBlock will help open the image and convert to a tensor, while MultiCategoryBlock will help with the multilabel classification."
      ],
      "metadata": {
        "id": "fzaktQsQEjPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create functions that will be used to open the images and get the categories of the image for the DataBlock."
      ],
      "metadata": {
        "id": "bbrxbgenEjPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/kaggle/input/clothing-dataset-full'\n",
        "def get_x(r): return path+'/images_original/'+r['image'] # create path to open images in the original folder\n",
        "def get_y(r): return r['label_cat'].split(' ') # split the labels using space as a delimitter"
      ],
      "metadata": {
        "trusted": true,
        "id": "He89sR0XEjPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataBlock\n",
        "dblock = DataBlock(blocks = (ImageBlock, MultiCategoryBlock),\n",
        "                  get_x = get_x, get_y = get_y,\n",
        "                  item_tfms = RandomResizedCrop(128, min_scale=0.35))  # ensure every item is of the same size\n",
        "dls = dblock.dataloaders(label_df) # collates items from dataset into minibatches"
      ],
      "metadata": {
        "trusted": true,
        "id": "qdDf3zO0EjPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can view the dataloader images and their subsequent labels."
      ],
      "metadata": {
        "id": "3JqXmKz6EjPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls.show_batch(nrows=3, ncols=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iJ1gIF-0EjPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Learner"
      ],
      "metadata": {
        "trusted": true,
        "id": "OJy9pBb5EjPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the DataLoader is ready, we can now create the learner with the threshold 0.2."
      ],
      "metadata": {
        "id": "v-Q_BD4uEjPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = cnn_learner(dls, resnet18, metrics=partial(accuracy_multi, thresh=0.2))\n",
        "learn.fine_tune(5, base_lr=3e-3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nDhuHskCEjPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using 5 epocs, we trained the last layer of the CNN with 18 layers and used the learning rate of 0.003. The 'fine_tune' function uses one epoch to train the final layer on the CNN and then unfreezes the entire model and trains all the 18 layers.  With 5 epochs, we have been able to gain a training accuracy of 96.48%. "
      ],
      "metadata": {
        "id": "T1RhV3NJEjPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the learner has been created, we can test different threshold values on the validation set to find the right value to predict the labels."
      ],
      "metadata": {
        "id": "hl_1uzFiEjPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Predictions and target variables\n",
        "preds,targs = learn.get_preds()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ahlgmu1kEjPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = torch.linspace(0.01,0.99,50)\n",
        "accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs] # get_preds applies sigmoid activation function\n",
        "plt.plot(xs,accs);"
      ],
      "metadata": {
        "trusted": true,
        "id": "eEQnwQWGEjPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictictions are high at the threshold value of 0.1 and above. The smoothness of the curve until what seems to be 0.9 shows that we wont be overfitting by picking a random value. Thus maintaining the threshold at 0.2 should result in non-biased predictions."
      ],
      "metadata": {
        "id": "gdaTxruQEjPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The learner can exported to deploy it on a server for an application. Run this notebook on JupyterNotebook server to use the following command to download the model as a .pkl file to the home directory."
      ],
      "metadata": {
        "id": "xkY7AbP8EjPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.export(Path(\"/kaggle/working/export.pkl\"))"
      ],
      "metadata": {
        "trusted": true,
        "id": "h_89K34nEjPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model will be stored in the home directory. To import it into you new application use 'load_learner(export.pkl)'"
      ],
      "metadata": {
        "id": "Nkcjr3pAEjPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test The Model"
      ],
      "metadata": {
        "id": "UJRT2hfjEjPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned above, the model is ready to be imported to a server for an end-to-end application. Although the model can be tested using iPython widgets. We can create a mini interface to upload images and classify them accordingly."
      ],
      "metadata": {
        "id": "BJ7JagcaEjPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload = widgets.FileUpload()\n",
        "out_image = widgets.Output()\n",
        "prediction = widgets.Label()\n",
        "run = widgets.Button(description='Classify')\n",
        "\n",
        "# btn_upload = widgets.FileUpload()\n",
        "# out_pl = widgets.Output()\n",
        "# lbl_pred = widgets.Label()\n",
        "# btn_run = widgets.Button(description='Classify')"
      ],
      "metadata": {
        "trusted": true,
        "id": "jDyUJ46HEjPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_click_classify(change):\n",
        "    img = PILImage.create(upload.data[-1])\n",
        "    out_image.clear_output()\n",
        "    with out_image: display(img.to_thumb(128,128))\n",
        "    pred,pred_idx,probs = learn.predict(img)\n",
        "    pred0 = pred[0]\n",
        "    pred1 = pred[1]\n",
        "    if pred0=='False':\n",
        "        prediction.value = f'This is a {pred1} for adults.'\n",
        "    else:\n",
        "        prediction.value = f'This is a {pred1} for kids.'\n",
        "\n",
        "run.on_click(on_click_classify)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zF7_FOxvEjPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Virtual Box to encapsulate the iPython widgets\n",
        "VBox([widgets.Label('Upload a picture of a pice of clothing!'), \n",
        "      upload, run, out_image, prediction])"
      ],
      "metadata": {
        "trusted": true,
        "id": "__Q_4BjpEjPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make use of this application, upload this notebook and run it in its entirety to test it out. This is just one example amomg many to prove that the model works! A full-fleged application can be used idenitfy multiple kinds of clothing that can lead to further processes as required to fulfil the needs of the user.\n",
        "\n",
        "Huge thanks to Alexey Grigorev for this dataset and to Jeremy Howard for the FastAI course."
      ],
      "metadata": {
        "id": "NjroYuZ4EjPw"
      }
    }
  ]
}